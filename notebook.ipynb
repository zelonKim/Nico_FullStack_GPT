{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of now, there are officially eight planets in our solar system. These planets are Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. However, it is important to note that there is ongoing debate and discussion regarding the status of Pluto as a planet. Pluto was reclassified as a \"dwarf planet\" by the International Astronomical Union (IAU) in 2006.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "a = chat.predict(\"How many planets are there?\")  # 모델 객체.predict(\"질문 내용\")을 통해 모델에 질문을 함.\n",
    "\n",
    "a \n",
    "# 'As of now, there are officially eight planets in our solar system. These planets are Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. However, it is important to note that there is ongoing debate and discussion regarding the status of Pluto as a planet. Pluto was reclassified as a \"dwarf planet\" by the International Astronomical Union (IAU) in 2006.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 저는 지리 전문가입니다. 멕시코와 태국 사이의 거리는 대략 17,000 킬로미터입니다. 제 이름은 폴이에요! 어떻게 도와드릴까요?')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1) # temperature속성을 통해 모델의 창의력을 설정해줌.\n",
    "\n",
    "messages = [ # 메세지 리스트\n",
    "    SystemMessage(content=\"You are geography expert. And you only reply in Korean.\"), # SystemMessage(content=\"모델 설정 내용\")\n",
    "    AIMessage(content=\"Hello, My Name is Paul!\"), # AIMessage(content=\"시작 인사말 내용\")\n",
    "    HumanMessage(content=\"What is the distance between Mexico and Thailand?\"), # HumanMessage(content=\"실제 질문 내용\")\n",
    "]\n",
    "\n",
    "a = chat.predict_messages(messages) # 모델 객체.predict_messages(메세지 리스트)를 통해 모델에 질문을 함. \n",
    "\n",
    "a\n",
    "# AIMessage(content='안녕하세요, 제 이름은 폴이에요! 멕시코와 태국 사이의 거리는 대략 17,000 킬로미터입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles).'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1) \n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    \"What is the distance between {country_a} and {country_b}\",\n",
    ") # PromptTemplate.from_template(\"질문 내용 {변수명}\")을 통해 템플릿 객체를 생성함.\n",
    "\n",
    "prompt = template.format(country_a=\"Mexico\", country_b=\"Thailand\") # 템플릿 객체.format(변수명=\"변수값\")를 통해 프롬프트를 생성함.\n",
    "\n",
    "\n",
    "a = chat.predict(prompt) # 모델 객체.predict(프롬프트)를 통해 모델에 질문을 함.\n",
    "\n",
    "a\n",
    "# 'The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles).'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='멕시코와 태국 사이의 거리는 약 17,000 킬로미터입니다.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1) \n",
    "\n",
    "template = ChatPromptTemplate.from_messages( # ChatPromptTemplate.from_messages([ 메세지 튜플{변수명} ])을 통해 템플릿 객체를 생성함.\n",
    "    [ \n",
    "        (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "        (\"ai\", \"Hello, my name is {name}!\"),\n",
    "        (\"human\", \"What is the distance between {country_a} and {country_b}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ChatPrompt = template.format_messages( # 템플릿 객체.format_messages(변수명=\"변수값\")을 통해 챗 프롬프트를 생성함.\n",
    "    language=\"Korean\",\n",
    "    name=\"Paul\",\n",
    "    country_a=\"Mexico\",\n",
    "    country_b=\"Thailand\"\n",
    ")\n",
    "\n",
    "a = chat.predict_messages(ChatPrompt) # 모델 객체.predict_messages(챗 프롬프트)를 통해 모델에 질문을 함.\n",
    "\n",
    "a\n",
    "# AIMessage(content='안녕하세요, 제 이름은 폴이에요! 멕시코와 태국 사이의 거리는 대략 17,000 킬로미터입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items =  text.strip().split(\",\")\n",
    "        return list(map(str.strip, items)) \n",
    "\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(\"Hello, how, are, you\")\n",
    "\n",
    "# ['Hello', 'how', 'are', 'you']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'orange',\n",
       " 'yellow',\n",
       " 'green',\n",
       " 'blue',\n",
       " 'indigo',\n",
       " 'violet',\n",
       " 'black',\n",
       " 'white',\n",
       " 'gray']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1) \n",
    "\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase. Do not reply with anything else.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(max_items=10, question=\"What are the colors?\")\n",
    "\n",
    "result = chat.predict_messages(prompt) \n",
    "result  # AIMessage(content='red, orange, yellow, green, blue, indigo, violet, black, white, gray')\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "parsedResult = p.parse(result.content)\n",
    "\n",
    "parsedResult\n",
    "\n",
    "# ['red',\n",
    "#  'orange',\n",
    "#  'yellow',\n",
    "#  'green',\n",
    "#  'blue',\n",
    "#  'indigo',\n",
    "#  'violet',\n",
    "#  'black',\n",
    "#  'white',\n",
    "#  'gray']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'orange',\n",
       " 'yellow',\n",
       " 'green',\n",
       " 'blue',\n",
       " 'indigo',\n",
       " 'violet',\n",
       " 'black',\n",
       " 'white',\n",
       " 'gray']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "chain.invoke ({\n",
    "    \"max_items\": 10,\n",
    "    \"question\": \"What are the colors?\"\n",
    "})\n",
    "\n",
    "# ['red',\n",
    "#  'orange',\n",
    "#  'yellow',\n",
    "#  'green',\n",
    "#  'blue',\n",
    "#  'indigo',\n",
    "#  'violet',\n",
    "#  'black',\n",
    "#  'white',\n",
    "#  'gray']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]) \n",
    "\n",
    "\n",
    "chef_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients.\"),\n",
    "    (\"human\", \"I want to cook {cuisine} food.\")\n",
    "])\n",
    "\n",
    "\n",
    "chef_chain = chef_template | chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it.\"),\n",
    "    (\"human\", \"{recipe}\")\n",
    "])\n",
    "\n",
    "veg_chain = veg_template | chat\n",
    "\n",
    "final_chain = {\"recipe\":chef_chain} | veg_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "    \"cuisine\": \"Korean\"\n",
    "})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Great choice! Korean cuisine is known for its bold flavors and unique combinations. Here's a recipe for a classic Korean dish called Bibimbap:\n",
    "\n",
    "Ingredients:\n",
    "- 2 cups cooked rice\n",
    "- 1 carrot, julienned\n",
    "- 1 zucchini, julienned\n",
    "- 1 cup spinach\n",
    "- 1 cup bean sprouts\n",
    "- 4 shiitake mushrooms, sliced\n",
    "- 1/2 pound beef (can be substituted with tofu or chicken), thinly sliced\n",
    "- 4 eggs\n",
    "- 2 tablespoons vegetable oil\n",
    "- 2 tablespoons soy sauce\n",
    "- 1 tablespoon sesame oil\n",
    "- 1 tablespoon gochujang (Korean chili paste)\n",
    "- Salt, to taste\n",
    "- Sesame seeds, for garnish\n",
    "- Kimchi, for serving (optional)\n",
    "\n",
    "Instructions:\n",
    "1. Cook the rice according to the package instructions and set aside.\n",
    "2. Blanch the spinach and bean sprouts in boiling water for 1-2 minutes. Drain and rinse with cold water. Squeeze out any excess water from the spinach and season with a pinch of salt and 1 teaspoon of sesame oil. Set aside.\n",
    "3. Heat 1 tablespoon of vegetable oil in a pan over medium heat. Stir-fry the carrots and zucchini for 2-3 minutes until slightly softened. Season with a pinch of salt and set aside.\n",
    "4. In the same pan, add another tablespoon of vegetable oil and cook the mushrooms until they are tender. Season with soy sauce and set aside.\n",
    "5. In a separate pan, cook the beef (or tofu/chicken) over medium-high heat until browned and cooked through. Season with soy sauce and set aside.\n",
    "6. In the same pan, fry the eggs sunny-side up or to your desired doneness.\n",
    "7. To assemble the bibimbap, divide the rice into four bowls. Arrange the cooked vegetables and beef (or tofu/chicken) on top of the rice.\n",
    "8. In a small bowl, mix together gochujang, 1 tablespoon of soy sauce, and 1 tablespoon of sesame oil. Drizzle this sauce over the rice and vegetables.\n",
    "9. Top each bowl with a fried egg and sprinkle with sesame seeds.\n",
    "10. Serve the bibimbap with kimchi on the side, if desired.\n",
    "\n",
    "Enjoy your homemade Korean Bibimbap!Great choice! Bibimbap is a delicious Korean dish that can easily be made vegetarian. Here's how you can make a vegetarian version of Bibimbap:\n",
    "\n",
    "Ingredients:\n",
    "- 2 cups cooked rice\n",
    "- 1 carrot, julienned\n",
    "- 1 zucchini, julienned\n",
    "- 1 cup spinach\n",
    "- 1 cup bean sprouts\n",
    "- 4 shiitake mushrooms, sliced\n",
    "- 1/2 pound tofu, thinly sliced\n",
    "- 4 eggs (optional, omit for a vegan version)\n",
    "- 2 tablespoons vegetable oil\n",
    "- 2 tablespoons soy sauce\n",
    "- 1 tablespoon sesame oil\n",
    "- 1 tablespoon gochujang (Korean chili paste)\n",
    "- Salt, to taste\n",
    "- Sesame seeds, for garnish\n",
    "- Kimchi, for serving (optional)\n",
    "\n",
    "Instructions:\n",
    "1. Cook the rice according to the package instructions and set aside.\n",
    "2. Blanch the spinach and bean sprouts in boiling water for 1-2 minutes. Drain and rinse with cold water. Squeeze out any excess water from the spinach and season with a pinch of salt and 1 teaspoon of sesame oil. Set aside.\n",
    "3. Heat 1 tablespoon of vegetable oil in a pan over medium heat. Stir-fry the carrots and zucchini for 2-3 minutes until slightly softened. Season with a pinch of salt and set aside.\n",
    "4. In the same pan, add another tablespoon of vegetable oil and cook the mushrooms until they are tender. Season with soy sauce and set aside.\n",
    "5. In a separate pan, cook the tofu over medium-high heat until browned and cooked through. Season with soy sauce and set aside.\n",
    "6. In a separate pan, fry the eggs sunny-side up or to your desired doneness (omit for a vegan version).\n",
    "7. To assemble the bibimbap, divide the rice into four bowls. Arrange the cooked vegetables and tofu on top of the rice.\n",
    "8. In a small bowl, mix together gochujang, 1 tablespoon of soy sauce, and 1 tablespoon of sesame oil. Drizzle this sauce over the rice and vegetables.\n",
    "9. Top each bowl with a fried egg (if using) and sprinkle with sesame seeds.\n",
    "10. Serve the bibimbap with kimchi on the side, if desired.\n",
    "\n",
    "Enjoy your homemade vegetarian Korean Bibimbap!\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]) \n",
    "\n",
    "t = PromptTemplate(\n",
    "    template=\"What is the capital of {country}\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "prompt = t.format(country=\"France\")\n",
    "\n",
    "chat.predict(prompt)\n",
    "\n",
    "# The capital of France is Paris.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher: \n",
      "I know this:\n",
      "Capital: Seoul\n",
      "Language: Korean\n",
      "Food: Kimchi and Bibimbap\n",
      "Currency: South Korean Won"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='Teacher: \\nI know this:\\nCapital: Seoul\\nLanguage: Korean\\nFood: Kimchi and Bibimbap\\nCurrency: South Korean Won')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]) \n",
    "\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_template = \"\"\"\n",
    "    Q: {question}\n",
    "    A: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples = examples,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\": \"Korea\"\n",
    "})\n",
    "\n",
    "\"\"\"\n",
    "Teacher: \n",
    "I know this:\n",
    "Capital: Seoul\n",
    "Language: Korean\n",
    "Food: Kimchi and Bibimbap\n",
    "Currency: South Korean Won\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        I know this:\n",
      "        Capital: Washington, D.C.\n",
      "        Language: English\n",
      "        Food: Hamburgers and Hotdogs\n",
      "        Currency: United States Dollar (USD)\n",
      "        "
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\n        I know this:\\n        Capital: Washington, D.C.\\n        Language: English\\n        Food: Hamburgers and Hotdogs\\n        Currency: United States Dollar (USD)\\n        ')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]) \n",
    "\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {   \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"Q\", \"what do you know about {country}?\"),\n",
    "    (\"A\", \"{answer}\")\n",
    "])\n",
    "\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples = examples,\n",
    ")\n",
    "\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert, you give short answers.\"),\n",
    "    example_prompt,\n",
    "    (\"human\", \"What do you know about {country}\")\n",
    "])\n",
    "\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\": \"USA\"\n",
    "})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "  I know this:\n",
    "        Capital: Washington, D.C.\n",
    "        Language: English\n",
    "        Food: Hamburgers and Hotdogs\n",
    "        Currency: United States Dollar (USD)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Q: What do you know about France?\\n    A: \\n        Here is what I know:\\n        Capital: Paris\\n        Language: French\\n        Food: Wine and Cheese\\n        Currency: Euro\\n        \\n\\n\\nQ: What do you know about Brazil?'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]) \n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "example_template = \"\"\"\n",
    "    Q: {question}\n",
    "    A: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples = examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=100,\n",
    ")\n",
    "\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    example_selector = example_selector,\n",
    "    suffix=\"Q: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "\n",
    "prompt.format(country=\"Brazil\")\n",
    "\n",
    "# '\\n    Q: What do you know about France?\\n    A: \\n        Here is what I know:\\n        Capital: Paris\\n        Language: French\\n        Food: Wine and Cheese\\n        Currency: Euro\\n        \\n\\n\\nQ: What do you know about Brazil?'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Q: What do you know about Italy?\\n    A: \\n        I know this:\\n        Capital: Rome\\n        Language: Italian\\n        Food: Pizza and Pasta\\n        Currency: Euro\\n        \\n\\n\\nQ: What do you know about Brazil?'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]) \n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "        return [choice(self.examples)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "example_template = \"\"\"\n",
    "    Q: {question}\n",
    "    A: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples = examples,\n",
    ")\n",
    "\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    example_selector = example_selector,\n",
    "    suffix=\"Q: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "\n",
    "prompt.format(country=\"Brazil\")\n",
    "# '\\n    Q: What do you know about France?\\n    A: \\n        Here is what I know:\\n        Capital: Paris\\n        Language: French\\n        Food: Wine and Cheese\\n        Currency: Euro\\n        \\n\\n\\nQ: What do you know about Brazil?'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
