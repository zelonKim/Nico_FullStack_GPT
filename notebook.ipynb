{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of now, there are officially eight planets in our solar system. These planets are Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. However, it is important to note that there is ongoing debate and discussion regarding the status of Pluto as a planet. Pluto was reclassified as a \"dwarf planet\" by the International Astronomical Union (IAU) in 2006.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "a = chat.predict(\"How many planets are there?\")  # 모델 객체.predict(\"질문 내용\")을 통해 모델에 질문을 함.\n",
    "\n",
    "a \n",
    "# 'As of now, there are officially eight planets in our solar system. These planets are Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. However, it is important to note that there is ongoing debate and discussion regarding the status of Pluto as a planet. Pluto was reclassified as a \"dwarf planet\" by the International Astronomical Union (IAU) in 2006.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 저는 지리 전문가입니다. 멕시코와 태국 사이의 거리는 대략 17,000 킬로미터입니다. 제 이름은 폴이에요! 어떻게 도와드릴까요?')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1) # temperature속성을 통해 모델의 창의력을 설정해줌.\n",
    "\n",
    "messages = [ # 메세지 리스트\n",
    "    SystemMessage(content=\"You are geography expert. And you only reply in Korean.\"), # SystemMessage(content=\"모델 설정 내용\")\n",
    "    AIMessage(content=\"Hello, My Name is Paul!\"), # AIMessage(content=\"시작 인사말 내용\")\n",
    "    HumanMessage(content=\"What is the distance between Mexico and Thailand?\"), # HumanMessage(content=\"실제 질문 내용\")\n",
    "]\n",
    "\n",
    "a = chat.predict_messages(messages) # 모델 객체.predict_messages(메세지 리스트)를 통해 모델에 질문을 함. \n",
    "\n",
    "a\n",
    "# AIMessage(content='안녕하세요, 제 이름은 폴이에요! 멕시코와 태국 사이의 거리는 대략 17,000 킬로미터입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles).'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1) \n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    \"What is the distance between {country_a} and {country_b}\",\n",
    ") # PromptTemplate.from_template(\"질문 내용 {변수명}\")을 통해 템플릿 객체를 생성함.\n",
    "\n",
    "prompt = template.format(country_a=\"Mexico\", country_b=\"Thailand\") # 템플릿 객체.format(변수명=\"변수값\")를 통해 프롬프트를 생성함.\n",
    "\n",
    "\n",
    "a = chat.predict(prompt) # 모델 객체.predict(프롬프트)를 통해 모델에 질문을 함.\n",
    "\n",
    "a\n",
    "# 'The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles).'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='멕시코와 태국 사이의 거리는 약 17,000 킬로미터입니다.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1) \n",
    "\n",
    "template = ChatPromptTemplate.from_messages( # ChatPromptTemplate.from_messages([ 메세지 튜플{변수명} ])을 통해 템플릿 객체를 생성함.\n",
    "    [ \n",
    "        (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "        (\"ai\", \"Hello, my name is {name}!\"),\n",
    "        (\"human\", \"What is the distance between {country_a} and {country_b}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ChatPrompt = template.format_messages( # 템플릿 객체.format_messages(변수명=\"변수값\")을 통해 챗 프롬프트를 생성함.\n",
    "    language=\"Korean\",\n",
    "    name=\"Paul\",\n",
    "    country_a=\"Mexico\",\n",
    "    country_b=\"Thailand\"\n",
    ")\n",
    "\n",
    "a = chat.predict_messages(ChatPrompt) # 모델 객체.predict_messages(챗 프롬프트)를 통해 모델에 질문을 함.\n",
    "\n",
    "a\n",
    "# AIMessage(content='안녕하세요, 제 이름은 폴이에요! 멕시코와 태국 사이의 거리는 대략 17,000 킬로미터입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items =  text.strip().split(\",\")\n",
    "        return list(map(str.strip, items)) \n",
    "\n",
    "\n",
    "p = CommaOutputParser()\n",
    "p.parse(\"Hello, how, are, you\")\n",
    "\n",
    "# ['Hello', 'how', 'are', 'you']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'orange',\n",
       " 'yellow',\n",
       " 'green',\n",
       " 'blue',\n",
       " 'indigo',\n",
       " 'violet',\n",
       " 'black',\n",
       " 'white',\n",
       " 'gray']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1) \n",
    "\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase. Do not reply with anything else.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(max_items=10, question=\"What are the colors?\")\n",
    "\n",
    "result = chat.predict_messages(prompt) \n",
    "result  # AIMessage(content='red, orange, yellow, green, blue, indigo, violet, black, white, gray')\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "parsedResult = p.parse(result.content)\n",
    "\n",
    "parsedResult\n",
    "\n",
    "# ['red',\n",
    "#  'orange',\n",
    "#  'yellow',\n",
    "#  'green',\n",
    "#  'blue',\n",
    "#  'indigo',\n",
    "#  'violet',\n",
    "#  'black',\n",
    "#  'white',\n",
    "#  'gray']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'orange',\n",
       " 'yellow',\n",
       " 'green',\n",
       " 'blue',\n",
       " 'indigo',\n",
       " 'violet',\n",
       " 'black',\n",
       " 'white',\n",
       " 'gray']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "chain.invoke ({\n",
    "    \"max_items\": 10,\n",
    "    \"question\": \"What are the colors?\"\n",
    "})\n",
    "\n",
    "# ['red',\n",
    "#  'orange',\n",
    "#  'yellow',\n",
    "#  'green',\n",
    "#  'blue',\n",
    "#  'indigo',\n",
    "#  'violet',\n",
    "#  'black',\n",
    "#  'white',\n",
    "#  'gray']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]) \n",
    "\n",
    "\n",
    "chef_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients.\"),\n",
    "    (\"human\", \"I want to cook {cuisine} food.\")\n",
    "])\n",
    "\n",
    "\n",
    "chef_chain = chef_template | chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it.\"),\n",
    "    (\"human\", \"{recipe}\")\n",
    "])\n",
    "\n",
    "veg_chain = veg_template | chat\n",
    "\n",
    "final_chain = {\"recipe\":chef_chain} | veg_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "    \"cuisine\": \"Korean\"\n",
    "})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Great choice! Korean cuisine is known for its bold flavors and unique combinations. Here's a recipe for a classic Korean dish called Bibimbap:\n",
    "\n",
    "Ingredients:\n",
    "- 2 cups cooked rice\n",
    "- 1 carrot, julienned\n",
    "- 1 zucchini, julienned\n",
    "- 1 cup spinach\n",
    "- 1 cup bean sprouts\n",
    "- 4 shiitake mushrooms, sliced\n",
    "- 1/2 pound beef (can be substituted with tofu or chicken), thinly sliced\n",
    "- 4 eggs\n",
    "- 2 tablespoons vegetable oil\n",
    "- 2 tablespoons soy sauce\n",
    "- 1 tablespoon sesame oil\n",
    "- 1 tablespoon gochujang (Korean chili paste)\n",
    "- Salt, to taste\n",
    "- Sesame seeds, for garnish\n",
    "- Kimchi, for serving (optional)\n",
    "\n",
    "Instructions:\n",
    "1. Cook the rice according to the package instructions and set aside.\n",
    "2. Blanch the spinach and bean sprouts in boiling water for 1-2 minutes. Drain and rinse with cold water. Squeeze out any excess water from the spinach and season with a pinch of salt and 1 teaspoon of sesame oil. Set aside.\n",
    "3. Heat 1 tablespoon of vegetable oil in a pan over medium heat. Stir-fry the carrots and zucchini for 2-3 minutes until slightly softened. Season with a pinch of salt and set aside.\n",
    "4. In the same pan, add another tablespoon of vegetable oil and cook the mushrooms until they are tender. Season with soy sauce and set aside.\n",
    "5. In a separate pan, cook the beef (or tofu/chicken) over medium-high heat until browned and cooked through. Season with soy sauce and set aside.\n",
    "6. In the same pan, fry the eggs sunny-side up or to your desired doneness.\n",
    "7. To assemble the bibimbap, divide the rice into four bowls. Arrange the cooked vegetables and beef (or tofu/chicken) on top of the rice.\n",
    "8. In a small bowl, mix together gochujang, 1 tablespoon of soy sauce, and 1 tablespoon of sesame oil. Drizzle this sauce over the rice and vegetables.\n",
    "9. Top each bowl with a fried egg and sprinkle with sesame seeds.\n",
    "10. Serve the bibimbap with kimchi on the side, if desired.\n",
    "\n",
    "Enjoy your homemade Korean Bibimbap!Great choice! Bibimbap is a delicious Korean dish that can easily be made vegetarian. Here's how you can make a vegetarian version of Bibimbap:\n",
    "\n",
    "Ingredients:\n",
    "- 2 cups cooked rice\n",
    "- 1 carrot, julienned\n",
    "- 1 zucchini, julienned\n",
    "- 1 cup spinach\n",
    "- 1 cup bean sprouts\n",
    "- 4 shiitake mushrooms, sliced\n",
    "- 1/2 pound tofu, thinly sliced\n",
    "- 4 eggs (optional, omit for a vegan version)\n",
    "- 2 tablespoons vegetable oil\n",
    "- 2 tablespoons soy sauce\n",
    "- 1 tablespoon sesame oil\n",
    "- 1 tablespoon gochujang (Korean chili paste)\n",
    "- Salt, to taste\n",
    "- Sesame seeds, for garnish\n",
    "- Kimchi, for serving (optional)\n",
    "\n",
    "Instructions:\n",
    "1. Cook the rice according to the package instructions and set aside.\n",
    "2. Blanch the spinach and bean sprouts in boiling water for 1-2 minutes. Drain and rinse with cold water. Squeeze out any excess water from the spinach and season with a pinch of salt and 1 teaspoon of sesame oil. Set aside.\n",
    "3. Heat 1 tablespoon of vegetable oil in a pan over medium heat. Stir-fry the carrots and zucchini for 2-3 minutes until slightly softened. Season with a pinch of salt and set aside.\n",
    "4. In the same pan, add another tablespoon of vegetable oil and cook the mushrooms until they are tender. Season with soy sauce and set aside.\n",
    "5. In a separate pan, cook the tofu over medium-high heat until browned and cooked through. Season with soy sauce and set aside.\n",
    "6. In a separate pan, fry the eggs sunny-side up or to your desired doneness (omit for a vegan version).\n",
    "7. To assemble the bibimbap, divide the rice into four bowls. Arrange the cooked vegetables and tofu on top of the rice.\n",
    "8. In a small bowl, mix together gochujang, 1 tablespoon of soy sauce, and 1 tablespoon of sesame oil. Drizzle this sauce over the rice and vegetables.\n",
    "9. Top each bowl with a fried egg (if using) and sprinkle with sesame seeds.\n",
    "10. Serve the bibimbap with kimchi on the side, if desired.\n",
    "\n",
    "Enjoy your homemade vegetarian Korean Bibimbap!\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]) \n",
    "\n",
    "t = PromptTemplate(\n",
    "    template=\"What is the capital of {country}\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "prompt = t.format(country=\"France\")\n",
    "\n",
    "chat.predict(prompt)\n",
    "\n",
    "# The capital of France is Paris.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher: \n",
      "I know this:\n",
      "Capital: Seoul\n",
      "Language: Korean\n",
      "Food: Kimchi and Bibimbap\n",
      "Currency: South Korean Won"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='Teacher: \\nI know this:\\nCapital: Seoul\\nLanguage: Korean\\nFood: Kimchi and Bibimbap\\nCurrency: South Korean Won')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]) \n",
    "\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_template = \"\"\"\n",
    "    Q: {question}\n",
    "    A: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples = examples,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\": \"Korea\"\n",
    "})\n",
    "\n",
    "\"\"\"\n",
    "Teacher: \n",
    "I know this:\n",
    "Capital: Seoul\n",
    "Language: Korean\n",
    "Food: Kimchi and Bibimbap\n",
    "Currency: South Korean Won\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        I know this:\n",
      "        Capital: Washington, D.C.\n",
      "        Language: English\n",
      "        Food: Hamburgers and Hotdogs\n",
      "        Currency: United States Dollar (USD)\n",
      "        "
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\n        I know this:\\n        Capital: Washington, D.C.\\n        Language: English\\n        Food: Hamburgers and Hotdogs\\n        Currency: United States Dollar (USD)\\n        ')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]) \n",
    "\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {   \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"Q\", \"what do you know about {country}?\"),\n",
    "    (\"A\", \"{answer}\")\n",
    "])\n",
    "\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples = examples,\n",
    ")\n",
    "\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert, you give short answers.\"),\n",
    "    example_prompt,\n",
    "    (\"human\", \"What do you know about {country}\")\n",
    "])\n",
    "\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\": \"USA\"\n",
    "})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "  I know this:\n",
    "        Capital: Washington, D.C.\n",
    "        Language: English\n",
    "        Food: Hamburgers and Hotdogs\n",
    "        Currency: United States Dollar (USD)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Q: What do you know about France?\\n    A: \\n        Here is what I know:\\n        Capital: Paris\\n        Language: French\\n        Food: Wine and Cheese\\n        Currency: Euro\\n        \\n\\n\\nQ: What do you know about Brazil?'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]) \n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "example_template = \"\"\"\n",
    "    Q: {question}\n",
    "    A: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples = examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=100,\n",
    ")\n",
    "\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    example_selector = example_selector,\n",
    "    suffix=\"Q: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "\n",
    "prompt.format(country=\"Brazil\")\n",
    "\n",
    "# '\\n    Q: What do you know about France?\\n    A: \\n        Here is what I know:\\n        Capital: Paris\\n        Language: French\\n        Food: Wine and Cheese\\n        Currency: Euro\\n        \\n\\n\\nQ: What do you know about Brazil?'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Q: What do you know about Italy?\\n    A: \\n        I know this:\\n        Capital: Rome\\n        Language: Italian\\n        Food: Pizza and Pasta\\n        Currency: Euro\\n        \\n\\n\\nQ: What do you know about Brazil?'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]) \n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "        return [choice(self.examples)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "example_template = \"\"\"\n",
    "    Q: {question}\n",
    "    A: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples = examples,\n",
    ")\n",
    "\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    example_selector = example_selector,\n",
    "    suffix=\"Q: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "\n",
    "prompt.format(country=\"Brazil\")\n",
    "# '\\n    Q: What do you know about France?\\n    A: \\n        Here is what I know:\\n        Capital: Paris\\n        Language: French\\n        Food: Wine and Cheese\\n        Currency: Euro\\n        \\n\\n\\nQ: What do you know about Brazil?'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Germany'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"./prompt.json\")\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Germany\")\n",
    "\n",
    "# 'What is the capital of Germany'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Germany'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Germany\")\n",
    "\n",
    "# 'What is the capital of Germany'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrrg! Me favorite food be a good ol' plate of rum-infused shrimp! The taste of those succulent crustaceans be like a party in me mouth, matey! Arg arg!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Arrrrg! Me favorite food be a good ol' plate of rum-infused shrimp! The taste of those succulent crustaceans be like a party in me mouth, matey! Arg arg!\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "                                     \n",
    "    {example}\n",
    "                              \n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start),\n",
    "]\n",
    "\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts,\n",
    ")\n",
    "\n",
    "\n",
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"character\": \"Pirate\",\n",
    "        \"example_question\": \"What is your location?\",\n",
    "        \"example_answer\": \"Arrrrg! That is a secret!! Arg arg!!\",\n",
    "        \"question\": \"What is your fav food?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Arrrrg! Me favorite food be a good ol' plate of rum-infused shrimp! The taste of those succulent crustaceans be like a party in me mouth, matey! Arg arg!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make italian pasta\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [23.92s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork or your fingers, gradually mix the eggs and salt into the flour, incorporating a little at a time.\\n4. Once the dough starts to come together, knead it with your hands until it forms a smooth and elastic ball. If the dough is too dry, you can add a little water, teaspoon by teaspoon, until it reaches the desired consistency. If it's too wet, add a little more flour.\\n5. Once the dough is formed, cover it with a clean kitchen towel or plastic wrap and let it rest for about 30 minutes. This allows the gluten to relax and makes the dough easier to work with.\\n6. After resting, divide the dough into smaller portions. You can use a pasta machine or a rolling pin to roll out the dough into thin sheets. If using a pasta machine, start with the widest setting and gradually decrease the thickness until you reach the desired thickness for your pasta.\\n7. Once the dough is rolled out, you can cut it into various shapes like spaghetti, fettuccine, or lasagna sheets. You can use a sharp knife or a pasta cutter for this.\\n8. As you cut the pasta, dust it with flour to prevent sticking. You can also hang the pasta on a drying rack or lay it flat on a clean surface until you're ready to cook it.\\n9. To cook the pasta, bring a large pot of salted water to a boil. Add the pasta and cook until al dente, which means it should still have a slight bite to it. The cooking time will vary depending on the thickness and shape of the pasta, so it's best to taste it as it cooks.\\n10. Once the pasta is cooked, drain it and toss it with your favorite sauce or toppings. Serve immediately and enjoy your homemade Italian pasta!\\n\\nNote: This recipe is for basic Italian pasta. There are many variations and types of pasta, so feel free to experiment with different ingredients and flavors to suit your preferences.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork or your fingers, gradually mix the eggs and salt into the flour, incorporating a little at a time.\\n4. Once the dough starts to come together, knead it with your hands until it forms a smooth and elastic ball. If the dough is too dry, you can add a little water, teaspoon by teaspoon, until it reaches the desired consistency. If it's too wet, add a little more flour.\\n5. Once the dough is formed, cover it with a clean kitchen towel or plastic wrap and let it rest for about 30 minutes. This allows the gluten to relax and makes the dough easier to work with.\\n6. After resting, divide the dough into smaller portions. You can use a pasta machine or a rolling pin to roll out the dough into thin sheets. If using a pasta machine, start with the widest setting and gradually decrease the thickness until you reach the desired thickness for your pasta.\\n7. Once the dough is rolled out, you can cut it into various shapes like spaghetti, fettuccine, or lasagna sheets. You can use a sharp knife or a pasta cutter for this.\\n8. As you cut the pasta, dust it with flour to prevent sticking. You can also hang the pasta on a drying rack or lay it flat on a clean surface until you're ready to cook it.\\n9. To cook the pasta, bring a large pot of salted water to a boil. Add the pasta and cook until al dente, which means it should still have a slight bite to it. The cooking time will vary depending on the thickness and shape of the pasta, so it's best to taste it as it cooks.\\n10. Once the pasta is cooked, drain it and toss it with your favorite sauce or toppings. Serve immediately and enjoy your homemade Italian pasta!\\n\\nNote: This recipe is for basic Italian pasta. There are many variations and types of pasta, so feel free to experiment with different ingredients and flavors to suit your preferences.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 13,\n",
      "      \"completion_tokens\": 493,\n",
      "      \"total_tokens\": 506\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork or your fingers, gradually mix the eggs and salt into the flour, incorporating a little at a time.\\n4. Once the dough starts to come together, knead it with your hands until it forms a smooth and elastic ball. If the dough is too dry, you can add a little water, teaspoon by teaspoon, until it reaches the desired consistency. If it's too wet, add a little more flour.\\n5. Once the dough is formed, cover it with a clean kitchen towel or plastic wrap and let it rest for about 30 minutes. This allows the gluten to relax and makes the dough easier to work with.\\n6. After resting, divide the dough into smaller portions. You can use a pasta machine or a rolling pin to roll out the dough into thin sheets. If using a pasta machine, start with the widest setting and gradually decrease the thickness until you reach the desired thickness for your pasta.\\n7. Once the dough is rolled out, you can cut it into various shapes like spaghetti, fettuccine, or lasagna sheets. You can use a sharp knife or a pasta cutter for this.\\n8. As you cut the pasta, dust it with flour to prevent sticking. You can also hang the pasta on a drying rack or lay it flat on a clean surface until you're ready to cook it.\\n9. To cook the pasta, bring a large pot of salted water to a boil. Add the pasta and cook until al dente, which means it should still have a slight bite to it. The cooking time will vary depending on the thickness and shape of the pasta, so it's best to taste it as it cooks.\\n10. Once the pasta is cooked, drain it and toss it with your favorite sauce or toppings. Serve immediately and enjoy your homemade Italian pasta!\\n\\nNote: This recipe is for basic Italian pasta. There are many variations and types of pasta, so feel free to experiment with different ingredients and flavors to suit your preferences.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "set_debug(True)\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "chat.predict(\"How do you make italian pasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make italian pasta\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [22.94s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork or your fingers, gradually mix the eggs and salt into the flour, incorporating a little bit at a time.\\n4. Once the dough starts to come together, knead it with your hands until it forms a smooth and elastic ball. If the dough is too dry, you can add a little water, one tablespoon at a time, until it reaches the desired consistency.\\n5. Once the dough is formed, cover it with a clean kitchen towel or plastic wrap and let it rest for about 30 minutes. This will allow the gluten to relax and make the dough easier to work with.\\n6. After resting, divide the dough into smaller portions, depending on the amount of pasta you want to make.\\n7. Take one portion of the dough and flatten it with your hands or a rolling pin until it is thin enough to fit through a pasta machine or to be rolled out by hand.\\n8. If using a pasta machine, start with the widest setting and pass the dough through it. Fold the dough in half and pass it through again. Repeat this process several times, gradually decreasing the width setting until you reach the desired thickness.\\n9. If rolling out by hand, use a rolling pin to roll the dough out as thin as possible, making sure to dust it with flour to prevent sticking.\\n10. Once the dough is rolled out, you can cut it into your desired pasta shape. For example, you can make fettuccine, tagliatelle, or lasagna sheets.\\n11. After cutting the pasta, you can cook it immediately in a pot of boiling salted water for a few minutes until al dente. Alternatively, you can let it dry for a few hours or overnight before cooking.\\n12. Serve the cooked pasta with your favorite sauce, such as marinara, carbonara, or pesto.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork or your fingers, gradually mix the eggs and salt into the flour, incorporating a little bit at a time.\\n4. Once the dough starts to come together, knead it with your hands until it forms a smooth and elastic ball. If the dough is too dry, you can add a little water, one tablespoon at a time, until it reaches the desired consistency.\\n5. Once the dough is formed, cover it with a clean kitchen towel or plastic wrap and let it rest for about 30 minutes. This will allow the gluten to relax and make the dough easier to work with.\\n6. After resting, divide the dough into smaller portions, depending on the amount of pasta you want to make.\\n7. Take one portion of the dough and flatten it with your hands or a rolling pin until it is thin enough to fit through a pasta machine or to be rolled out by hand.\\n8. If using a pasta machine, start with the widest setting and pass the dough through it. Fold the dough in half and pass it through again. Repeat this process several times, gradually decreasing the width setting until you reach the desired thickness.\\n9. If rolling out by hand, use a rolling pin to roll the dough out as thin as possible, making sure to dust it with flour to prevent sticking.\\n10. Once the dough is rolled out, you can cut it into your desired pasta shape. For example, you can make fettuccine, tagliatelle, or lasagna sheets.\\n11. After cutting the pasta, you can cook it immediately in a pot of boiling salted water for a few minutes until al dente. Alternatively, you can let it dry for a few hours or overnight before cooking.\\n12. Serve the cooked pasta with your favorite sauce, such as marinara, carbonara, or pesto.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 13,\n",
      "      \"completion_tokens\": 470,\n",
      "      \"total_tokens\": 483\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork or your fingers, gradually mix the eggs and salt into the flour, incorporating a little bit at a time.\\n4. Once the dough starts to come together, knead it with your hands until it forms a smooth and elastic ball. If the dough is too dry, you can add a little water, one tablespoon at a time, until it reaches the desired consistency.\\n5. Once the dough is formed, cover it with a clean kitchen towel or plastic wrap and let it rest for about 30 minutes. This will allow the gluten to relax and make the dough easier to work with.\\n6. After resting, divide the dough into smaller portions, depending on the amount of pasta you want to make.\\n7. Take one portion of the dough and flatten it with your hands or a rolling pin until it is thin enough to fit through a pasta machine or to be rolled out by hand.\\n8. If using a pasta machine, start with the widest setting and pass the dough through it. Fold the dough in half and pass it through again. Repeat this process several times, gradually decreasing the width setting until you reach the desired thickness.\\n9. If rolling out by hand, use a rolling pin to roll the dough out as thin as possible, making sure to dust it with flour to prevent sticking.\\n10. Once the dough is rolled out, you can cut it into your desired pasta shape. For example, you can make fettuccine, tagliatelle, or lasagna sheets.\\n11. After cutting the pasta, you can cook it immediately in a pot of boiling salted water for a few minutes until al dente. Alternatively, you can let it dry for a few hours or overnight before cooking.\\n12. Serve the cooked pasta with your favorite sauce, such as marinara, carbonara, or pesto.\\n\\nEnjoy your homemade Italian pasta!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache(\"cache.db\"))\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "chat.predict(\"How do you make italian pasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork or your fingers, gradually mix the eggs and salt into the flour, incorporating a little at a time.\\n4. Once the dough starts to come together, knead it with your hands until it forms a smooth and elastic ball. If the dough is too dry, you can add a little water, teaspoon by teaspoon, until it reaches the desired consistency. If it's too wet, add a little more flour.\\n5. Once the dough is formed, cover it with a clean kitchen towel or plastic wrap and let it rest for about 30 minutes. This will allow the gluten to relax and make the dough easier to work with.\\n6. After resting, divide the dough into smaller portions. Take one portion and flatten it with your hands or a rolling pin until it's about 1/4 inch thick.\\n7. If you have a pasta machine, you can use it to roll out the dough to your desired thickness. Start with the widest setting and gradually decrease it until you reach the desired thickness. If you don't have a pasta machine, you can continue rolling the dough with a rolling pin until it's thin enough.\\n8. Once the dough is rolled out, you can cut it into your desired pasta shape. For example, you can make fettuccine by cutting the dough into long, thin strips, or you can make ravioli by cutting it into squares and filling them with your desired filling.\\n9. After cutting the pasta, you can cook it immediately in a pot of boiling salted water for about 2-3 minutes, or until al dente. Alternatively, you can let the pasta dry for a few hours or overnight before cooking it.\\n10. Once cooked, drain the pasta and serve it with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chat.predict(\"How do you make italian pasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the recipe for soju\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [1ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Here is a simple recipe for making soju at home:\\n\\nIngredients:\\n- 1 cup of rice\\n- 1 cup of nuruk (a Korean fermentation starter)\\n- 8 cups of water\\n- 1 tablespoon of yeast (optional, for faster fermentation)\\n- Sugar (optional, for sweetness)\\n\\nInstructions:\\n1. Rinse the rice thoroughly and soak it in water for about 1 hour.\\n2. Drain the soaked rice and transfer it to a large pot. Add 8 cups of water and bring it to a boil.\\n3. Reduce the heat to low and simmer the rice for about 30 minutes, or until it becomes soft and mushy.\\n4. Remove the pot from heat and let it cool down to room temperature.\\n5. Once the rice has cooled, transfer it to a large fermentation container or jar.\\n6. Add the nuruk to the container and mix it well with the rice. If you want a faster fermentation process, you can also add yeast at this stage.\\n7. Cover the container with a clean cloth or plastic wrap and secure it tightly.\\n8. Store the container in a cool, dark place for about 7-10 days, allowing it to ferment. Stir the mixture once a day to prevent mold formation.\\n9. After the fermentation period, strain the mixture through a cheesecloth or fine mesh strainer to remove any solids.\\n10. If desired, you can add sugar to taste and mix well until it dissolves.\\n11. Transfer the strained liquid to a clean bottle or container and refrigerate it for a few hours before serving.\\n12. Soju is traditionally served chilled in small shot glasses. Enjoy responsibly!\\n\\nNote: This recipe is a simplified version of homemade soju. Traditional soju-making processes can be more complex and time-consuming.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Here is a simple recipe for making soju at home:\\n\\nIngredients:\\n- 1 cup of rice\\n- 1 cup of nuruk (a Korean fermentation starter)\\n- 8 cups of water\\n- 1 tablespoon of yeast (optional, for faster fermentation)\\n- Sugar (optional, for sweetness)\\n\\nInstructions:\\n1. Rinse the rice thoroughly and soak it in water for about 1 hour.\\n2. Drain the soaked rice and transfer it to a large pot. Add 8 cups of water and bring it to a boil.\\n3. Reduce the heat to low and simmer the rice for about 30 minutes, or until it becomes soft and mushy.\\n4. Remove the pot from heat and let it cool down to room temperature.\\n5. Once the rice has cooled, transfer it to a large fermentation container or jar.\\n6. Add the nuruk to the container and mix it well with the rice. If you want a faster fermentation process, you can also add yeast at this stage.\\n7. Cover the container with a clean cloth or plastic wrap and secure it tightly.\\n8. Store the container in a cool, dark place for about 7-10 days, allowing it to ferment. Stir the mixture once a day to prevent mold formation.\\n9. After the fermentation period, strain the mixture through a cheesecloth or fine mesh strainer to remove any solids.\\n10. If desired, you can add sugar to taste and mix well until it dissolves.\\n11. Transfer the strained liquid to a clean bottle or container and refrigerate it for a few hours before serving.\\n12. Soju is traditionally served chilled in small shot glasses. Enjoy responsibly!\\n\\nNote: This recipe is a simplified version of homemade soju. Traditional soju-making processes can be more complex and time-consuming.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the recipe for bread\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [17.25s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Here is a basic recipe for making bread:\\n\\nIngredients:\\n- 4 cups all-purpose flour\\n- 2 teaspoons active dry yeast\\n- 2 teaspoons salt\\n- 2 teaspoons sugar\\n- 2 cups warm water (around 110°F/43°C)\\n- 2 tablespoons olive oil (optional)\\n\\nInstructions:\\n1. In a large mixing bowl, combine the flour, yeast, salt, and sugar. Mix well.\\n2. Gradually add the warm water to the dry ingredients, stirring with a wooden spoon or your hands until a sticky dough forms.\\n3. If desired, drizzle the olive oil over the dough and knead it for about 5 minutes until it becomes smooth and elastic. This step is optional but can add flavor and texture to the bread.\\n4. Cover the bowl with a clean kitchen towel or plastic wrap and let the dough rise in a warm place for about 1-2 hours, or until it doubles in size.\\n5. Preheat your oven to 425°F (220°C) and place a baking stone or baking sheet inside to preheat as well.\\n6. Once the dough has risen, gently punch it down to release any air bubbles. Transfer it to a lightly floured surface and shape it into a loaf or desired shape.\\n7. Place the shaped dough onto the preheated baking stone or baking sheet. If desired, you can make a few shallow cuts on the top of the loaf with a sharp knife to allow for expansion during baking.\\n8. Bake the bread for about 25-30 minutes, or until it turns golden brown and sounds hollow when tapped on the bottom.\\n9. Remove the bread from the oven and let it cool on a wire rack before slicing and serving.\\n\\nNote: This is a basic bread recipe, and you can customize it by adding ingredients like herbs, cheese, nuts, or seeds to the dough for added flavor and texture.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Here is a basic recipe for making bread:\\n\\nIngredients:\\n- 4 cups all-purpose flour\\n- 2 teaspoons active dry yeast\\n- 2 teaspoons salt\\n- 2 teaspoons sugar\\n- 2 cups warm water (around 110°F/43°C)\\n- 2 tablespoons olive oil (optional)\\n\\nInstructions:\\n1. In a large mixing bowl, combine the flour, yeast, salt, and sugar. Mix well.\\n2. Gradually add the warm water to the dry ingredients, stirring with a wooden spoon or your hands until a sticky dough forms.\\n3. If desired, drizzle the olive oil over the dough and knead it for about 5 minutes until it becomes smooth and elastic. This step is optional but can add flavor and texture to the bread.\\n4. Cover the bowl with a clean kitchen towel or plastic wrap and let the dough rise in a warm place for about 1-2 hours, or until it doubles in size.\\n5. Preheat your oven to 425°F (220°C) and place a baking stone or baking sheet inside to preheat as well.\\n6. Once the dough has risen, gently punch it down to release any air bubbles. Transfer it to a lightly floured surface and shape it into a loaf or desired shape.\\n7. Place the shaped dough onto the preheated baking stone or baking sheet. If desired, you can make a few shallow cuts on the top of the loaf with a sharp knife to allow for expansion during baking.\\n8. Bake the bread for about 25-30 minutes, or until it turns golden brown and sounds hollow when tapped on the bottom.\\n9. Remove the bread from the oven and let it cool on a wire rack before slicing and serving.\\n\\nNote: This is a basic bread recipe, and you can customize it by adding ingredients like herbs, cheese, nuts, or seeds to the dough for added flavor and texture.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 13,\n",
      "      \"completion_tokens\": 387,\n",
      "      \"total_tokens\": 400\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "Here is a simple recipe for making soju at home:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup of rice\n",
      "- 1 cup of nuruk (a Korean fermentation starter)\n",
      "- 8 cups of water\n",
      "- 1 tablespoon of yeast (optional, for faster fermentation)\n",
      "- Sugar (optional, for sweetness)\n",
      "\n",
      "Instructions:\n",
      "1. Rinse the rice thoroughly and soak it in water for about 1 hour.\n",
      "2. Drain the soaked rice and transfer it to a large pot. Add 8 cups of water and bring it to a boil.\n",
      "3. Reduce the heat to low and simmer the rice for about 30 minutes, or until it becomes soft and mushy.\n",
      "4. Remove the pot from heat and let it cool down to room temperature.\n",
      "5. Once the rice has cooled, transfer it to a large fermentation container or jar.\n",
      "6. Add the nuruk to the container and mix it well with the rice. If you want a faster fermentation process, you can also add yeast at this stage.\n",
      "7. Cover the container with a clean cloth or plastic wrap and secure it tightly.\n",
      "8. Store the container in a cool, dark place for about 7-10 days, allowing it to ferment. Stir the mixture once a day to prevent mold formation.\n",
      "9. After the fermentation period, strain the mixture through a cheesecloth or fine mesh strainer to remove any solids.\n",
      "10. If desired, you can add sugar to taste and mix well until it dissolves.\n",
      "11. Transfer the strained liquid to a clean bottle or container and refrigerate it for a few hours before serving.\n",
      "12. Soju is traditionally served chilled in small shot glasses. Enjoy responsibly!\n",
      "\n",
      "Note: This recipe is a simplified version of homemade soju. Traditional soju-making processes can be more complex and time-consuming. Here is a basic recipe for making bread:\n",
      "\n",
      "Ingredients:\n",
      "- 4 cups all-purpose flour\n",
      "- 2 teaspoons active dry yeast\n",
      "- 2 teaspoons salt\n",
      "- 2 teaspoons sugar\n",
      "- 2 cups warm water (around 110°F/43°C)\n",
      "- 2 tablespoons olive oil (optional)\n",
      "\n",
      "Instructions:\n",
      "1. In a large mixing bowl, combine the flour, yeast, salt, and sugar. Mix well.\n",
      "2. Gradually add the warm water to the dry ingredients, stirring with a wooden spoon or your hands until a sticky dough forms.\n",
      "3. If desired, drizzle the olive oil over the dough and knead it for about 5 minutes until it becomes smooth and elastic. This step is optional but can add flavor and texture to the bread.\n",
      "4. Cover the bowl with a clean kitchen towel or plastic wrap and let the dough rise in a warm place for about 1-2 hours, or until it doubles in size.\n",
      "5. Preheat your oven to 425°F (220°C) and place a baking stone or baking sheet inside to preheat as well.\n",
      "6. Once the dough has risen, gently punch it down to release any air bubbles. Transfer it to a lightly floured surface and shape it into a loaf or desired shape.\n",
      "7. Place the shaped dough onto the preheated baking stone or baking sheet. If desired, you can make a few shallow cuts on the top of the loaf with a sharp knife to allow for expansion during baking.\n",
      "8. Bake the bread for about 25-30 minutes, or until it turns golden brown and sounds hollow when tapped on the bottom.\n",
      "9. Remove the bread from the oven and let it cool on a wire rack before slicing and serving.\n",
      "\n",
      "Note: This is a basic bread recipe, and you can customize it by adding ingredients like herbs, cheese, nuts, or seeds to the dough for added flavor and texture. \n",
      "\n",
      "Tokens Used: 400\n",
      "\tPrompt Tokens: 13\n",
      "\tCompletion Tokens: 387\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0007935\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "    a = chat.predict(\"What is the recipe for soju\")\n",
    "    b = chat.predict(\"What is the recipe for bread\")\n",
    "    print(a, b, \"\\n\")\n",
    "    print(usage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.openai import OpenAI\n",
    "\n",
    "chat = OpenAI(\n",
    "    temperature=0.1,\n",
    "    max_tokens=450,\n",
    "    model=\"gpt-3.5-turbo-16k\"\n",
    ")\n",
    "\n",
    "chat.save(\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gimseongjin/FullStack_GPT/env/lib/python3.11/site-packages/langchain/llms/openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/gimseongjin/FullStack_GPT/env/lib/python3.11/site-packages/langchain/llms/openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAIChat(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo-16k', model_kwargs={'temperature': 0.1, 'max_tokens': 450, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "chat = load_llm(\"model.json\")\n",
    "\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi'), AIMessage(content='How are you?')]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory # stores whole previous messages \n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.save_context({\"input\": \"Hi\"}, {\"output\": \"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi'),\n",
       "  AIMessage(content='How are you?'),\n",
       "  HumanMessage(content='Hi'),\n",
       "  AIMessage(content='How are you?')]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "memory.save_context({\"input\": \"Hi\"}, {\"output\": \"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi'),\n",
       "  AIMessage(content='How are you?'),\n",
       "  HumanMessage(content='Hi'),\n",
       "  AIMessage(content='How are you?'),\n",
       "  HumanMessage(content='Hi'),\n",
       "  AIMessage(content='How are you?')]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "memory.save_context({\"input\": \"Hi\"}, {\"output\": \"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory # stores only recent previous message\n",
    "\n",
    "\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True, \n",
    "    k=4 # how many store\n",
    ")\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "add_message(1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(2, 2)\n",
    "add_message(3, 3)\n",
    "add_message(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='1'),\n",
       "  AIMessage(content='1'),\n",
       "  HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4')]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4'),\n",
       "  HumanMessage(content='5'),\n",
       "  AIMessage(content='5')]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"summary\": \"\",\n",
      "  \"new_lines\": \"Human: Hi I'm Nicolas, I live in South Korea\\nAI: Wow that is so cool!\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:LLMChain > 2:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\n\\n\\nNew lines of conversation:\\nHuman: Hi I'm Nicolas, I live in South Korea\\nAI: Wow that is so cool!\\n\\nNew summary:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:LLMChain > 2:llm:ChatOpenAI] [2.71s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The human introduces themselves as Nicolas and mentions that they live in South Korea. The AI responds with enthusiasm, saying that it thinks that is cool.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The human introduces themselves as Nicolas and mentions that they live in South Korea. The AI responds with enthusiasm, saying that it thinks that is cool.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 155,\n",
      "      \"completion_tokens\": 29,\n",
      "      \"total_tokens\": 184\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LLMChain] [2.71s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"The human introduces themselves as Nicolas and mentions that they live in South Korea. The AI responds with enthusiasm, saying that it thinks that is cool.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.memory import ConversationSummaryMemory \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"summary\": \"The human introduces themselves as Nicolas and mentions that they live in South Korea. The AI responds with enthusiasm, saying that it thinks that is cool and expresses a desire to visit because it thinks South Korea is pretty.\",\n",
      "  \"new_lines\": \"Human: South Kddorea is so pretty\\nAI: I wish I could go!!!\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:LLMChain > 2:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\nThe human introduces themselves as Nicolas and mentions that they live in South Korea. The AI responds with enthusiasm, saying that it thinks that is cool and expresses a desire to visit because it thinks South Korea is pretty.\\n\\nNew lines of conversation:\\nHuman: South Kddorea is so pretty\\nAI: I wish I could go!!!\\n\\nNew summary:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:LLMChain > 2:llm:ChatOpenAI] [4.04s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The human introduces themselves as Nicolas and mentions that they live in South Korea. The AI responds with enthusiasm, saying that it thinks that is cool and expresses a desire to visit because it thinks South Korea is pretty. The human agrees and says that South Korea is indeed very beautiful, to which the AI responds by expressing its own wish to visit.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The human introduces themselves as Nicolas and mentions that they live in South Korea. The AI responds with enthusiasm, saying that it thinks that is cool and expresses a desire to visit because it thinks South Korea is pretty. The human agrees and says that South Korea is indeed very beautiful, to which the AI responds by expressing its own wish to visit.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 194,\n",
      "      \"completion_tokens\": 68,\n",
      "      \"total_tokens\": 262\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LLMChain] [4.04s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"The human introduces themselves as Nicolas and mentions that they live in South Korea. The AI responds with enthusiasm, saying that it thinks that is cool and expresses a desire to visit because it thinks South Korea is pretty. The human agrees and says that South Korea is indeed very beautiful, to which the AI responds by expressing its own wish to visit.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "add_message(\"South Korea is so pretty\", \"I wish I could go!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'The human introduces themselves as Nicolas and mentions that they live in South Korea. The AI responds with enthusiasm, saying that it thinks that is cool and expresses a desire to visit because it thinks South Korea is pretty. The human agrees and says that South Korea is indeed very beautiful, to which the AI responds by expressing its own wish to visit.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory # ConversationSummaryMemory + ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=80, # If it exceeds the max_token_limit, oldest conversation will be summarized\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Nicolas, I live in South Korea\"),\n",
       "  AIMessage(content='Wow that is so cool!')]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"South Korea is so pretty\", \"I wish I could go!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Nicolas, I live in South Korea\"),\n",
       "  AIMessage(content='Wow that is so cool!'),\n",
       "  HumanMessage(content='South Korea is so pretty'),\n",
       "  AIMessage(content='I wish I could go!!!')]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"How far is Korea from Argentina?\", \"I don`t know! Super far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Nicolas, I live in South Korea\"),\n",
       "  AIMessage(content='Wow that is so cool!'),\n",
       "  HumanMessage(content='South Korea is so pretty'),\n",
       "  AIMessage(content='I wish I could go!!!'),\n",
       "  HumanMessage(content='How far is Korea from Argentina?'),\n",
       "  AIMessage(content='I don`t know! Super far!')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"hahaha, Let me show you my photo for korea\", \"sure. Thank you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human introduces themselves as Nicolas and mentions that they live in South Korea. The AI responds by expressing excitement and finding it cool.'),\n",
       "  HumanMessage(content='South Korea is so pretty'),\n",
       "  AIMessage(content='I wish I could go!!!'),\n",
       "  HumanMessage(content='How far is Korea from Argentina?'),\n",
       "  AIMessage(content='I don`t know! Super far!'),\n",
       "  HumanMessage(content='hahaha, Let me show you my photo for korea'),\n",
       "  AIMessage(content='sure. Thank you')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"How about Korean view and sight\", \"It is so good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human introduces themselves as Nicolas and mentions that they live in South Korea. The AI responds by expressing excitement and finding it cool. The human then mentions that South Korea is pretty, to which the AI responds by expressing a desire to go there.'),\n",
       "  HumanMessage(content='How far is Korea from Argentina?'),\n",
       "  AIMessage(content='I don`t know! Super far!'),\n",
       "  HumanMessage(content='hahaha, Let me show you my photo for korea'),\n",
       "  AIMessage(content='sure. Thank you'),\n",
       "  HumanMessage(content='How about Korean view and sight'),\n",
       "  AIMessage(content='It is so good')]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory # Only extract most important thing\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Nicolas: Nicolas is a person. Nicolas lives in South Korea.')]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\": \"who is Nicolas\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"Nicolas likes kimchi\", \"Wow that is so cool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Nicolas: Nicolas is a person. Nicolas lives in South Korea. Nicolas likes kimchi.')]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"inputs\": \"what does nicolas like\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"people call me nico.?\", \"Yes, I have seen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Nicolas: Nicolas is a person. Nicolas lives in South Korea. Nicolas likes kimchi.'),\n",
       "  SystemMessage(content='On people: people call nico.')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"inputs\": \"how nicolas is called by people\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Nicolas: Nicolas is a person. Nicolas lives in South Korea. Nicolas likes kimchi.')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"inputs\": \"where nicolas is popular?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mMy name is Nico\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Nico! How can I assist you today?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    ")\n",
    "\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(\"{question}\"),\n",
    "    verbose=True, \n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is Nico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI live in Seoul\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great! Seoul is the capital and largest city of South Korea. It is known for its vibrant culture, modern architecture, and delicious food. There are many attractions to explore in Seoul, such as Gyeongbokgung Palace, N Seoul Tower, Myeongdong shopping district, and the Han River. It's also a hub for technology and innovation, with numerous tech companies and startups based in the city. Enjoy your time in Seoul!\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in Seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat is my name?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human introduces themselves as Nico and mentions that they live in Seoul. The AI responds by providing information about Seoul, including its vibrant culture, modern architecture, delicious food, and various attractions. The AI also mentions that Seoul is a hub for technology and innovation.\\nHuman: What is my name?\\nAI: I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation.\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "    \n",
      "    Human: My name is Nico\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Nico! How can I assist you today?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a helpful AI talking to a human.\n",
    "    {chat_history}\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),\n",
    "    verbose=True, \n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is Nico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "    Human: My name is Nico\n",
      "AI: Hello Nico! How can I assist you today?\n",
      "    Human: I live in Seoul\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great! Seoul is a vibrant and bustling city. How can I assist you today, Nico?\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in Seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "    Human: My name is Nico\n",
      "AI: Hello Nico! How can I assist you today?\n",
      "Human: I live in Seoul\n",
      "AI: That's great! Seoul is a vibrant and bustling city. How can I assist you today, Nico?\n",
      "Human: What is your name?\n",
      "AI: I am an AI assistant and do not have a personal name. You can simply refer to me as AI. How can I assist you further, Nico?\n",
      "    Human: What is my name?\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Nico.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "    System: The human introduces themselves as Nico.\n",
      "AI: Hello Nico! How can I assist you today?\n",
      "Human: I live in Seoul\n",
      "AI: That's great! Seoul is a vibrant and bustling city. How can I assist you today, Nico?\n",
      "Human: What is your name?\n",
      "AI: I am an AI assistant and do not have a personal name. You can simply refer to me as AI. How can I assist you further, Nico?\n",
      "Human: What is my name?\n",
      "AI: Your name is Nico.\n",
      "    Human: I live in Seoul\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great! Seoul is a vibrant and bustling city. How can I assist you today, Nico?\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in Seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "    System: The human introduces themselves as Nico. The AI greets Nico and asks how it can assist them. Nico mentions that they live in Seoul, and the AI acknowledges that Seoul is a vibrant and bustling city. The AI then asks again how it can assist Nico.\n",
      "Human: What is your name?\n",
      "AI: I am an AI assistant and do not have a personal name. You can simply refer to me as AI. How can I assist you further, Nico?\n",
      "Human: What is my name?\n",
      "AI: Your name is Nico.\n",
      "Human: I live in Seoul\n",
      "AI: That's great! Seoul is a vibrant and bustling city. How can I assist you today, Nico?\n",
      "    Human: What is my name?\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Nico. How can I assist you today?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': \"System: Nico introduces themselves and the AI greets them, acknowledging that they live in Seoul. The AI asks how it can assist Nico. Nico then asks the AI for its name, to which the AI responds that it is an AI assistant and does not have a personal name. Nico can simply refer to it as AI. The AI asks again how it can assist Nico.\\nHuman: What is my name?\\nAI: Your name is Nico.\\nHuman: I live in Seoul\\nAI: That's great! Seoul is a vibrant and bustling city. How can I assist you today, Nico?\\nHuman: What is my name?\\nAI: Your name is Nico. How can I assist you today?\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is Nico\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Nico! How can I assist you today?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True, \n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is Nico\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "\n",
    "def load_memory(input):\n",
    "    print(input)\n",
    "    return memory.load_memory_variables({})[\"chat_history\"]\n",
    "\n",
    "\n",
    "chain = RunnablePassthrough.assign(chat_history=load_memory) | prompt | llm\n",
    "\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\n",
    "        \"question\": question\n",
    "    })\n",
    "    memory.save_context({\"input\": question}, {\"output\": result.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'My name is Nico'}\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"My name is nico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'My name is Nico'}\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "\n",
    "def load_memory(input):\n",
    "    print(input)\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\n",
    "        \"question\": question\n",
    "    })\n",
    "    memory.save_context({\"input\": question}, {\"output\": result.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "\n",
    "def load_memory():\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "chain =  prompt | llm\n",
    "\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"history\":load_memory()\n",
    "    })\n",
    "    memory.save_context({\"input\": question}, {\"output\": result.content})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
