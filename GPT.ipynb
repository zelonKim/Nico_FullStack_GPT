{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gimseongjin/FullStack_GPT/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Potato is a starchy vegetable that is grown underground in rows in a shallow, well-drained soil. It is a tuber, which means it is an underground, fleshy part of the plant that stores nutrients. Potatoes are a popular food source and are used in many different dishes, including salads, soups, stews, and baked dishes. They are also used as a source of starch for making paper and other products. Potatoes are high in carbohydrates and are a good source of fiber, vitamin C, and potassium.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"[INST]What is the meaning of {word}[/INST]\")\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\":250,\n",
    "    },\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\n",
    "    \"word\": \"potato\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gimseongjin/FullStack_GPT/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using pad_token, but it is not set yet.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' kind of green cheese on the side that grows in the soil or in soil in soil, and it will also form its own vineyard or tree. The potato has become so adapted to being so hard and hard to move around that it can never be found without it. You can find potato growing under certain very cold temperatures and even under very hot places as long as there is water. Also, while the potato can be used as a grain instead of a food product and it is a fairly cheap way to grow and store potato, it is not nearly as nutritious for those who want it as it is for those who want its use on the table.\\n\\nThe potato is very hard on the liver and can get eaten quickly by children.\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"A {word} is a\")\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"gpt2\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\": 150\n",
    "    },\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\n",
    "    \"word\": \"potato\"\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GPT4All\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"A {word} is a\")\n",
    "\n",
    "llm = GPT4All(\n",
    "   model=\"./falcon.bin\",\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\n",
    "    \"word\": \"potato\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"lon\": \"126.9779\",\\n  \"lat\": \"37.5665\"\\n}'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "def get_weather(lon, lat):\n",
    "    print(\"call an api...\")\n",
    "\n",
    "\n",
    "function = {\n",
    "    \"name\": \"get_weather\",\n",
    "\n",
    "    \"description\": \"function that takes longitude and latitude to find the weather of the place\",\n",
    "\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"lon\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The longitude coordinate\"\n",
    "            },\n",
    "            \"lat\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The latitude coordinate\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"required\": [\"lon\", \"lat\"]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ").bind(\n",
    "    function_call = \"auto\",\n",
    "    functions=[function]\n",
    ")\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"How is the weather in {city}\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"city\": \"seoul\"})\n",
    "\n",
    "response = response.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call an api...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "r = json.loads(response)\n",
    "\n",
    "get_weather(r[\"lon\"], r[\"lat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"questions\": [\\n    {\\n      \"question\": \"What is the capital city of South Korea?\",\\n      \"answers\": [\\n        {\\n          \"answer\": \"Seoul\",\\n          \"correct\": true\\n        },\\n        {\\n          \"answer\": \"Busan\",\\n          \"correct\": false\\n        },\\n        {\\n          \"answer\": \"Incheon\",\\n          \"correct\": false\\n        },\\n        {\\n          \"answer\": \"Daegu\",\\n          \"correct\": false\\n        }\\n      ]\\n    },\\n    {\\n      \"question\": \"Which river flows through Seoul?\",\\n      \"answers\": [\\n        {\\n          \"answer\": \"Han River\",\\n          \"correct\": true\\n        },\\n        {\\n          \"answer\": \"Nakdong River\",\\n          \"correct\": false\\n        },\\n        {\\n          \"answer\": \"Geum River\",\\n          \"correct\": false\\n        },\\n        {\\n          \"answer\": \"Yeongsan River\",\\n          \"correct\": false\\n        }\\n      ]\\n    },\\n    {\\n      \"question\": \"What is the tallest building in Seoul?\",\\n      \"answers\": [\\n        {\\n          \"answer\": \"Lotte World Tower\",\\n          \"correct\": true\\n        },\\n        {\\n          \"answer\": \"N Seoul Tower\",\\n          \"correct\": false\\n        },\\n        {\\n          \"answer\": \"63 Building\",\\n          \"correct\": false\\n        },\\n        {\\n          \"answer\": \"Seoul Sky\",\\n          \"correct\": false\\n        }\\n      ]\\n    },\\n    {\\n      \"question\": \"Which palace is located in the heart of Seoul?\",\\n      \"answers\": [\\n        {\\n          \"answer\": \"Gyeongbokgung Palace\",\\n          \"correct\": true\\n        },\\n        {\\n          \"answer\": \"Changdeokgung Palace\",\\n          \"correct\": false\\n        },\\n        {\\n          \"answer\": \"Deoksugung Palace\",\\n          \"correct\": false\\n        },\\n        {\\n          \"answer\": \"Changgyeonggung Palace\",\\n          \"correct\": false\\n        }\\n      ]\\n    },\\n    {\\n      \"question\": \"What is the famous shopping district in Seoul?\",\\n      \"answers\": [\\n        {\\n          \"answer\": \"Myeongdong\",\\n          \"correct\": true\\n        },\\n        {\\n          \"answer\": \"Gangnam\",\\n          \"correct\": false\\n        },\\n        {\\n          \"answer\": \"Hongdae\",\\n          \"correct\": false\\n        },\\n        {\\n          \"answer\": \"Dongdaemun\",\\n          \"correct\": false\\n        }\\n      ]\\n    }\\n  ]\\n}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "function = {\n",
    "    \"name\": \"create_quiz\",\n",
    "\n",
    "    \"description\": \"function that takes a list of questions and answers and returns a quiz\",\n",
    "    \n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"questions\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"question\": {\n",
    "                            \"type\": \"string\",\n",
    "                        },\n",
    "                        \"answers\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"answer\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                    },\n",
    "                                    \"correct\": {\n",
    "                                        \"type\": \"boolean\",\n",
    "                                    },\n",
    "                                },\n",
    "                                \"required\": [\"answer\", \"correct\"],\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"question\", \"answers\"],\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"questions\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ").bind(\n",
    "    function_call={\n",
    "        \"name\": \"create_quiz\",\n",
    "    },\n",
    "    functions=[\n",
    "        function,\n",
    "    ],\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Make a quiz about {city}\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"city\": \"Seoul\"})\n",
    "\n",
    "\n",
    "response = response.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for question in json.loads(response)[\"questions\"]:\n",
    "    print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess \n",
    "from pydub import AudioSegment  \n",
    "import math\n",
    "\n",
    "\n",
    "def extract_audio_from_video(video_path, audio_path):\n",
    "    command = [\"ffmpeg\", \"-i\", video_path, \"-vn\", audio_path]\n",
    "    subprocess.run(command) \n",
    "\n",
    "# extract_audio_from_video(\"./files/podcast.mp4\", \"./files/podcast.mp3\")\n",
    "\n",
    "\n",
    "\n",
    "def cut_audio_in_chunks(audio_path, chunk_size, chunks_folder):\n",
    "    track = AudioSegment.from_mp3(audio_path)\n",
    "    chunk_len = chunk_size * 60 * 1000\n",
    "    chunks = math.ceil(len(track) / chunk_len)\n",
    "\n",
    "    for i in range(chunks):\n",
    "        start_time = i * chunk_len\n",
    "        end_time = (i+1) * chunk_len\n",
    "        \n",
    "        chunk = track[start_time : end_time]\n",
    "        chunk.export(f\"{chunks_folder}/chunk_{i}.mp3\", format=\"mp3\")\n",
    "\n",
    "# cut_audio_in_chunks(\"./files/podcast.mp3\", 10, \"./files/chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import glob  \n",
    "\n",
    "\n",
    "def transcribe_chunks(chunk_folder, destination):\n",
    "    files = glob.glob(f\"{chunk_folder}/*.mp3\")\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, \"rb\") as audio_file,  open(destination, \"a\") as text_file:\n",
    "            \n",
    "            transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "            text_file.write(transcript[\"text\"])\n",
    "\n",
    "# transcribe_chunks(\"./files/chunks\", \"./files/transcript.txt\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./.cache/chunks/chunk_0.mp3',\n",
       " './.cache/chunks/chunk_1.mp3',\n",
       " './.cache/chunks/chunk_2.mp3',\n",
       " './.cache/chunks/chunk_3.mp3',\n",
       " './.cache/chunks/chunk_4.mp3',\n",
       " './.cache/chunks/chunk_5.mp3',\n",
       " './.cache/chunks/chunk_6.mp3',\n",
       " './.cache/chunks/chunk_7.mp3']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob(\"./.cache/chunks/*.mp3\")\n",
    "\n",
    "files.sort() # sort by ascending order\n",
    "\n",
    "files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The total cost is $5,467.38.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "prompt = \"Cost of $355.39 + $924.87 + $721.2 + $1940.29 + $573.63 + $65.72 + $35.00 + $552.00 + $76.16 + $29.12\"\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo calculate the sum of these numbers, I will use the Sum Calculator tool. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Sum Calculator\",\n",
      "  \"action_input\": {\n",
      "    \"a\": 355.39,\n",
      "    \"b\": 924.87\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1280.26\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the sum of the first two numbers to be 1280.26. Now I will continue to calculate the sum of the remaining numbers. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Sum Calculator\",\n",
      "  \"action_input\": {\n",
      "    \"a\": 1280.26,\n",
      "    \"b\": 721.2\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m2001.46\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the sum of the first two numbers to be 1280.26. Now I will continue to calculate the sum of the remaining numbers. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Sum Calculator\",\n",
      "  \"action_input\": {\n",
      "    \"a\": 2001.46,\n",
      "    \"b\": 1940.29\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m3941.75\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the sum of the first three numbers to be 2001.46. Now I will continue to calculate the sum of the remaining numbers. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Sum Calculator\",\n",
      "  \"action_input\": {\n",
      "    \"a\": 3941.75,\n",
      "    \"b\": 573.63\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m4515.38\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the sum of the first four numbers to be 3941.75. Now I will continue to calculate the sum of the remaining numbers. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Sum Calculator\",\n",
      "  \"action_input\": {\n",
      "    \"a\": 4515.38,\n",
      "    \"b\": 65.72\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m4581.1\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the sum of the first five numbers to be 4515.38. Now I will continue to calculate the sum of the remaining numbers. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Sum Calculator\",\n",
      "  \"action_input\": {\n",
      "    \"a\": 4581.1,\n",
      "    \"b\": 35.00\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m4616.1\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the sum of the first six numbers to be 4581.1. Now I will continue to calculate the sum of the remaining numbers. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Sum Calculator\",\n",
      "  \"action_input\": {\n",
      "    \"a\": 4616.1,\n",
      "    \"b\": 552.00\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m5168.1\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the sum of the first seven numbers to be 4616.1. Now I will continue to calculate the sum of the remaining numbers. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Sum Calculator\",\n",
      "  \"action_input\": {\n",
      "    \"a\": 5168.1,\n",
      "    \"b\": 76.16\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m5244.26\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the sum of the first eight numbers to be 5168.1. Now I will continue to calculate the sum of the remaining numbers. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Sum Calculator\",\n",
      "  \"action_input\": {\n",
      "    \"a\": 5244.26,\n",
      "    \"b\": 29.12\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m5273.38\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the sum of the first nine numbers to be 5244.26. Now I will calculate the sum of the last number. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Sum Calculator\",\n",
      "  \"action_input\": {\n",
      "    \"a\": 5273.38,\n",
      "    \"b\": 29.12\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m5302.5\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the sum of all the numbers to be 5302.5. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The sum of $355.39 + $924.87 + $721.2 + $1940.29 + $573.63 + $65.72 + $35.00 + $552.00 + $76.16 + $29.12 is $5302.5.\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Cost of $355.39 + $924.87 + $721.2 + $1940.29 + $573.63 + $65.72 + $35.00 + $552.00 + $76.16 + $29.12',\n",
       " 'output': 'The sum of $355.39 + $924.87 + $721.2 + $1940.29 + $573.63 + $65.72 + $35.00 + $552.00 + $76.16 + $29.12 is $5302.5.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "\n",
    "\n",
    "def plus(a, b):\n",
    "    return a + b\n",
    "\n",
    "agent = initialize_agent(\n",
    "    llm=llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, # tools` function can have multiple parameters\n",
    "    verbose=True,\n",
    "    tools=[\n",
    "        StructuredTool.from_function(\n",
    "            func=plus, \n",
    "            name=\"Sum Calculator\",\n",
    "            description=\"Use this to perform sums of two numbers. This tool take two arguments, both should be numbers.\"\n",
    "    )  \n",
    "])\n",
    "\n",
    "\n",
    "prompt = \"Cost of $355.39 + $924.87 + $721.2 + $1940.29 + $573.63 + $65.72 + $35.00 + $552.00 + $76.16 + $29.12\"\n",
    "\n",
    "agent.invoke(prompt) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the Sum Calculator to add up all the given numbers.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to use the Sum Calculator to add up all the given numbers.\n",
      "Action: Sum Calculator\n",
      "Action Input: 355.39,924.87\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1280.26\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the sum of the first two numbers. Now I need to add the next number.\n",
      "Action: Sum Calculator\n",
      "Action Input: 1280.26,721.2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m2001.46\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the sum of the first three numbers. Now I need to add the next number.\n",
      "Action: Sum Calculator\n",
      "Action Input: 2001.46,1940.29\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m3941.75\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the sum of the first four numbers. Now I need to add the next number.\n",
      "Action: Sum Calculator\n",
      "Action Input: 3941.75,573.63\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m4515.38\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the sum of the first five numbers. Now I need to add the next number.\n",
      "Action: Sum Calculator\n",
      "Action Input: 4515.38,65.72\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m4581.1\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the sum of the first six numbers. Now I need to add the next number.\n",
      "Action: Sum Calculator\n",
      "Action Input: 4581.1,35.00\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m4616.1\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the sum of the first seven numbers. Now I need to add the next number.\n",
      "Action: Sum Calculator\n",
      "Action Input: 4616.1,552.00\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m5168.1\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the sum of the first eight numbers. Now I need to add the next number.\n",
      "Action: Sum Calculator\n",
      "Action Input: 5168.1,76.16\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m5244.26\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the sum of the first nine numbers. Now I need to add the last number.\n",
      "Action: Sum Calculator\n",
      "Action Input: 5244.26,29.12\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m5273.38\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer. \n",
      "Final Answer: The sum of $355.39 + $924.87 + $721.2 + $1940.29 + $573.63 + $65.72 + $35.00 + $552.00 + $76.16 + $29.12 is $5273.38.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Cost of $355.39 + $924.87 + $721.2 + $1940.29 + $573.63 + $65.72 + $35.00 + $552.00 + $76.16 + $29.12',\n",
       " 'output': 'The sum of $355.39 + $924.87 + $721.2 + $1940.29 + $573.63 + $65.72 + $35.00 + $552.00 + $76.16 + $29.12 is $5273.38.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import Tool\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "\n",
    "\n",
    "def plus(inputs):\n",
    "    a, b = inputs.split(\",\")\n",
    "    return float(a) + float(b)\n",
    "\n",
    "\n",
    "agent = initialize_agent(\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # tools` function can have only single parameter\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    tools=[\n",
    "        Tool.from_function(\n",
    "            func=plus,\n",
    "            name=\"Sum Calculator\",\n",
    "            description=\"Use this to perform sums of two numbers. Use this tool by sending a pair of number separated by a comma.\\n Example:1,2\"\n",
    "    )  \n",
    "])\n",
    "\n",
    "prompt = \"Cost of $355.39 + $924.87 + $721.2 + $1940.29 + $573.63 + $65.72 + $35.00 + $552.00 + $76.16 + $29.12\"\n",
    "\n",
    "\n",
    "agent.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `CalculatorTool` with `{'a': 355.39, 'b': 924.87}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m1280.26\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `CalculatorTool` with `{'a': 1280.26, 'b': 721.2}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m2001.46\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `CalculatorTool` with `{'a': 2001.46, 'b': 1940.29}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m3941.75\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `CalculatorTool` with `{'a': 3941.75, 'b': 573.63}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m4515.38\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `CalculatorTool` with `{'a': 4515.38, 'b': 65.72}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m4581.1\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `CalculatorTool` with `{'a': 4581.1, 'b': 35.0}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m4616.1\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `CalculatorTool` with `{'a': 4616.1, 'b': 552.0}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5168.1\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `CalculatorTool` with `{'a': 5168.1, 'b': 76.16}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5244.26\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `CalculatorTool` with `{'a': 5244.26, 'b': 29.12}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5273.38\u001b[0m\u001b[32;1m\u001b[1;3mThe cost of $355.39 + $924.87 + $721.2 + $1940.29 + $573.63 + $65.72 + $35.00 + $552.00 + $76.16 + $29.12 is $5273.38.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Cost of $355.39 + $924.87 + $721.2 + $1940.29 + $573.63 + $65.72 + $35.00 + $552.00 + $76.16 + $29.12',\n",
       " 'output': 'The cost of $355.39 + $924.87 + $721.2 + $1940.29 + $573.63 + $65.72 + $35.00 + $552.00 + $76.16 + $29.12 is $5273.38.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import Tool, BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Type\n",
    "import requests\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "\n",
    "\n",
    "class CalculatorToolArgsSchema(BaseModel):\n",
    "    a: float = Field(description=\"The first number\")\n",
    "    b: float = Field(description=\"The second number\")\n",
    "    \n",
    "\n",
    "\n",
    "class CalculatorTool(BaseTool):\n",
    "    name = \"CalculatorTool\"\n",
    "    description = \"\"\"\n",
    "        Use this to perform sums of two numbers.\n",
    "        The first and second arguments should be numbers.\n",
    "        Only receives two arguments.\n",
    "    \"\"\"\n",
    "    args_schema: Type[CalculatorToolArgsSchema] = CalculatorToolArgsSchema\n",
    "\n",
    "    def _run(self, a, b):\n",
    "        return a + b\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "agent = initialize_agent(\n",
    "    llm=llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    tools=[\n",
    "        CalculatorTool(),\n",
    "])\n",
    "\n",
    "\n",
    "prompt = \"Cost of $355.39 + $924.87 + $721.2 + $1940.29 + $573.63 + $65.72 + $35.00 + $552.00 + $76.16 + $29.12\"\n",
    "\n",
    "agent.invoke(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
      "Action Input: \u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mdirectors, movies\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should query the schema of the directors and movies tables to see what columns I can use to find the highest grossing films.\n",
      "Action: sql_db_schema\n",
      "Action Input: directors, movies\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE directors (\n",
      "\tname TEXT, \n",
      "\tid INTEGER, \n",
      "\tgender INTEGER, \n",
      "\tuid INTEGER, \n",
      "\tdepartment TEXT, \n",
      "\tPRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from directors table:\n",
      "name\tid\tgender\tuid\tdepartment\n",
      "James Cameron\t4762\t2\t2710\tDirecting\n",
      "Gore Verbinski\t4763\t2\t1704\tDirecting\n",
      "Sam Mendes\t4764\t2\t39\tDirecting\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE movies (\n",
      "\tid INTEGER, \n",
      "\toriginal_title VARCHAR, \n",
      "\tbudget INTEGER, \n",
      "\tpopularity INTEGER, \n",
      "\trelease_date TEXT, \n",
      "\trevenue INTEGER, \n",
      "\ttitle TEXT, \n",
      "\tvote_average REAL, \n",
      "\tvote_count INTEGER, \n",
      "\toverview TEXT, \n",
      "\ttagline TEXT, \n",
      "\tuid INTEGER, \n",
      "\tdirector_id INTEGER DEFAULT 0 NOT NULL, \n",
      "\tPRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from movies table:\n",
      "id\toriginal_title\tbudget\tpopularity\trelease_date\trevenue\ttitle\tvote_average\tvote_count\toverview\ttagline\tuid\tdirector_id\n",
      "43597\tAvatar\t237000000\t150\t2009-12-10\t2787965087\tAvatar\t7.2\t11800\tIn the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, but \tEnter the World of Pandora.\t19995\t4762\n",
      "43598\tPirates of the Caribbean: At World's End\t300000000\t139\t2007-05-19\t961000000\tPirates of the Caribbean: At World's End\t6.9\t4500\tCaptain Barbossa, long believed to be dead, has come back to life and is headed to the edge of the E\tAt the end of the world, the adventure begins.\t285\t4763\n",
      "43599\tSpectre\t245000000\t107\t2015-10-26\t880674609\tSpectre\t6.3\t4466\tA cryptic message from Bond’s past sends him on a trail to uncover a sinister organization. While M \tA Plan No One Escapes\t206647\t4764\n",
      "*/\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI can use the revenue column from the movies table to find the highest grossing films and then join that with the directors table to find the directors.\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT directors.name, SUM(movies.revenue) AS total_revenue\n",
      "FROM directors\n",
      "JOIN movies ON directors.id = movies.director_id\n",
      "GROUP BY directors.name\n",
      "ORDER BY total_revenue DESC\n",
      "LIMIT 5\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[('Steven Spielberg', 9147393164), ('Peter Jackson', 6498642820), ('James Cameron', 5883569439), ('Michael Bay', 5832524638), ('Christopher Nolan', 4227483234)]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The 5 directors that have the highest grossing films are Steven Spielberg, Peter Jackson, James Cameron, Michael Bay, and Christopher Nolan.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Give me the 5 directors that have the highest grossing films.',\n",
       " 'output': 'The 5 directors that have the highest grossing films are Steven Spielberg, Peter Jackson, James Cameron, Michael Bay, and Christopher Nolan.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_sql_agent, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    model_name=\"gpt-3.5-turbo-1106\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///movies.sqlite\")\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "\n",
    "\n",
    "agent = create_sql_agent(\n",
    "    llm = llm,\n",
    "    toolkit = toolkit,\n",
    "    agent_type = AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "agent.invoke(\"Give me the 5 directors that have the highest grossing films.\")\n",
    "\n",
    "# toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import os\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    environment=\"gcp-starter\"\n",
    ")\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder()\n",
    "\n",
    "loader = CSVLoader(\"./recipes.csv\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embedder = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "vector_store = Pinecone.from_documents(docs, embedder, index_name=\"recipes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=': 740\\nhref: https://veganuary.com/recipes/korean-temple-kimchi/\\ntitle: Vegan Korean Temple Kimchi\\ningredients: Ingredients\\n\\n2 cabbages\\n3 cups Red Chilli Powder (Gochugaru)\\n½ cup Naturally Brewed Soy Sauce\\n2 cups Glutinous Rice Porridge\\nKorean Raspberry Extract ½ cup\\n20g Green Sea Fingers (Cheonggak)\\n½ cups Cooked Soybean (boiled and mashed into a paste)\\nSalt\\npreparation: Method\\n\\nRemove the base of the green sea fingers and finely chop them until they form a soft paste.\\nMix in a large bowl the glutinous rice porridge, red chili powder, prepared green sea fingers, prepared soybean, soy sauce and Korean raspberry extract. Season the mixture using salt (about 1 Tbsp). Leave the paste to rest for about 2 hours.\\nMix three handfuls of salt into a large bowl of water and soak the cabbage.\\nCut the cabbages vertically in half and make small cuts in the roots. Mix three handfuls of salt into a large bowl of water and soak the cabbage for a minute or so.\\nSpread a generous amount of salt in between the leaves (coarse sea salt works best); add even more to the stems. Leave for as long as possible to rest – from 3 to 12 hours.\\nRemove any excess brine from the cabbages and spread the prepared seasoning paste between the leaves.\\nCover the cabbages using the outermost leaves and store them in containers to ferment.', metadata={'row': 740.0, 'source': './recipes.csv'}),\n",
       " Document(page_content=': 1369\\nhref: https://simple-veganista.com/kimchi/\\ntitle: VEGAN KIMCHI\\ningredients: Ingredients\\n\\n\\n\\nScale\\n1x2x3x \\n\\n\\n\\n\\n1 medium Napa cabbage, about 2 lbs (savoy, green or any combo works too)\\n1/4 cup kosher, sea salt or other coarse salt\\n6 cups water\\n3/4 sweet apple (I used fuji), chopped\\n1/2 small white onion, chopped\\n1 1/2 inch ginger, chopped\\n1 – 2 cloves garlic\\n3 tablespoons Korean red chili powder (gochugaru) or 1 tablespoon each cayenne & Hungarian paprika\\n3 – 4 scallions (green onions), sliced 1 inch\\npreparation: Instructions\\n\\n\\nPreparing Cabbage: Quarter cabbage and chop laterally into about 2 inch pieces. Place cabbage in an extra large bowl or pot. Combine salt with 2 cups of lukewarm water, stir to dissolve salt. Pour salt water over the cabbage and add remaining 4 cups, stir to mix. If you can, place a plate or circular baking dish of sorts on top to submerge the cabbage (I used a pie dish), place something with a good amount of weight on top to hold down if necessary (it’s not completely necessary but will help to evenly wilt the cabbage). Give cabbage a good mix every now and then. Let soak for 2 hours, up to 12 if you like. I found that 2 – 4 hours was enough and didn’t see much change between the two times.\\nMake your seasonings: While cabbage is soaking, combine apple, onion, ginger and garlic in food processor/blender and process until fairly smooth.\\nIn a small bowl, mix the chili pepper with a small amount of water to make a wet paste. You can just as easily blend it with the apple/onion mixture adding a couple tablespoons of water as well.\\nMix everything together: Once cabbage is ready, drain water, reserving 1/2 cup, and rinse well. Place cabbage back in large bowl, combine with the scallions, apple/onion mixture and chili paste. Mix well to coat all pieces. Either use your hands (with gloves on pref to protect from the chili pepper) or simply use wooden spoons to toss everything.\\nPacking: Place the kimchi in glass jars or containers with lid, pack down the best you can to close air pockets and leave about an inch at the top for air and gases. Top with remaining juices, add reserved brine if needed to cover vegetables.\\nFermenting: Let kimchi sit at room temp (or in a cool place like a pantry or closet if weather is extremely warm) for 24 – 36 hours. After 24 hours, open kimchi and pack the mixture down with a spoon (the cabbage will have likely shrunk and you’ll have more liquids). You may notice it bubbling, this is perfectly normal as the kimchi is fermenting. As your kimchi ferments the flavors will develop, taste every 24 hours and place kimchi in the refrigerator once you’re happy with the taste and to slow fermentation, usually after 36 – 48 hours. It should be tangy, spicy and slightly sweet. After moving to the fridge, it’s best used within a month, maybe two.\\nMakes about 3 – 4 cups\\nServe with rice, use in Kimchi Fried Rice or make Kimchi Tofu Scramble!', metadata={'row': 1369.0, 'source': './recipes.csv'}),\n",
       " Document(page_content=': 1104\\nhref: https://simple-veganista.com/kimchi-fried-rice/\\ntitle: Vegan Kimchi Fried Rice\\ningredients: Ingredients\\n\\n\\n\\nUnits\\nUSM \\n\\nScale\\n1x2x3x \\n\\n\\n\\n\\n1 cup dried rice (or 3 cups cooked)\\n1 tablespoon sesame oil\\n1 – 2 cloves garlic, minced\\n1 inch knob ginger, grated or minced\\n1 cup frozen veggie mix (anything with carrots, peas, corn and/or green beans)\\n1 – 1 1/2 cups Vegan Kimchi (the more the merrier), chop the kimchi if you like\\n1 tablespoon tamari, soy sauce or coconut aminos, or to taste\\n1 tablespoon gochujang, or to taste (optional)\\n\\nTo garnish\\n\\n1 nori sheet, thinly sliced\\n2 scallions, thinly sliced (pale green + green parts only)\\nsesame seeds (white, black, toasted or combo)\\npreparation: Instructions\\n\\n\\nRice: Cook the rice according to package directions. For best results, use day old rice.\\nStir-fry: In a wok or pan, heat the oil over medium-high heat, add the garlic and ginger, cook until fragrant, about 30 – 60 seconds, stirring frequently. Add the rice, kimchi and frozen veggies, give a good mix, add the tamari and optional gochujang, stir fry for 3 – 4 minutes, or until most of the liquids have been absorbed. Taste for flavor, adding more tamari or chili pepper flakes.\\nServe: Spoon into individual bowls with sliced nori sheets, scallions and sesame seeds.\\nStore: Leftovers can be kept in the refrigerator for up to 3 days in a covered container. For longer storage, keep in the freezer for up to 2 – 3 months. Let thaw before reheating on the stovetop or microwave.', metadata={'row': 1104.0, 'source': './recipes.csv'}),\n",
       " Document(page_content=': 430\\nhref: https://veganuary.com/recipes/stuffed-cucumber-kimchi/\\ntitle: Stuffed Cucumber Kimchi\\ningredients: Ingredients\\n\\n1 large cucumber\\n10 Radishes\\n1 large (Asian) pear, or two small pears\\nPurified Water\\n3 Tbsp Naturally Brewed Soy Sauce\\n1 Cup Salt\\n3 Tbsp green plum extract\\npreparation: Method\\n\\nWash the cucumbers with salt to cleanse thoroughly. Soak the prepared cucumbers in boiling salted water.\\nMeanwhile, finely shred ½ of the pear(s) and the radishes. Add 1 Tbsp soy sauce and 1 Tbsp plum extract to the prepared pear and radishes, and mix well with your hands.\\nGrate the remainder of the pears and sieve or strain to collect juice. Add the purified water, 2 Tbsp soy sauce, 2 Tbsp plum extract and a pinch of salt to the juice.\\nCut the cucumber into 3cm cylindrical pieces and make cross-cuts on the circular face of each piece. Stuff the cucumbers with the radish and pear mixture and transfer to a plate. To finish, pour the pear juice mixture over the cucumber pieces.', metadata={'row': 430.0, 'source': './recipes.csv'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pinecone\n",
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    environment=\"gcp-starter\"\n",
    ")\n",
    "\n",
    "embedder = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "vector_store = Pinecone.from_existing_index(\"recipes\", embedder)\n",
    "\n",
    "\n",
    "docs = vector_store.similarity_search(\"kimchi\")\n",
    "\n",
    "docs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
